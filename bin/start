docker-compose run --rm server create_db
## Run server manage entrypoint. This runs
## /app/manage.py users create_root [admin_email] admin --password [admin_email]
## This command is to create a base line admin user. 
DEFAULT_EMAIL="user@pgadmin4.web"

export $(cat env) | xargs 
docker-compose run --rm server manage users create_root --password ${REDASH_ADMIN_PASSWORD} ${DEFAULT_EMAIL} admin 

## Retrieve the API Key from the first user we created
ADMIN_API_KEY=$(docker-compose run --rm postgres psql -d $REDASH_DATABASE_URL -c "SELECT api_key FROM public.users" | sed -n '3 p' | sed -e 's/^[[:space:]]*//' -e 's/[[:space:]]*$//')

HOST_IP_ADDRESS=server:5000
POSTGRES_DB_NAME="postgres"
POSTGRES_DB_USER="postgres"

## Run server manage entrypoint. This runs
## /app/manage.py manage ds new --type pg --options 
## This will create the first datasource that will be hold the cell data

### Data source options JSON format to populate the database
DATASOURCE_OPTIONS_JSON_FMT='{"dbname":"%s","host":"%s","port":5432,"password":"%s","user":"%s"}'
DATASOURCE_OPTIONS_JSON_STRING=$(printf "$DATASOURCE_OPTIONS_JSON_FMT" $POSTGRES_DB_NAME $HOST_IP_ADDRESS $POSTGRES_PASSWORD $POSTGRES_DB_USER)

## Add the first datasource
docker-compose run --rm server manage ds new --type pg --options ${DATASOURCE_OPTIONS_JSON_STRING} "battery_archive"

## Run the comp
docker-compose up 

## Add all of the pre-built queries now
## This needs to be done after bringing up the docker-compose stack. Reliant on nginx being ready
##sudo python3 scripts/redash_queries/query_import.py --api-key=$ADMIN_API_KEY --redash-url=$HOST_IP_ADDRESS

docker run --env-file ./env -v $(pwd):/app -e python /app/scripts/redash_queries/query_import.py --api-key=$ADMIN_API_KEY --redash-url=http://$HOST_IP_ADDRESS

#(sudo python3 scripts/redash_queries/query_import.py --api-key=$ADMIN_API_KEY --redash-url=http://$HOST_IP_ADDRESS
